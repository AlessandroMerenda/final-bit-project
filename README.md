# GlobalStay Data Engineering Project ğŸ¨

**Una pipeline ETL completa con Machine Learning per dati di prenotazioni alberghiere**

## ğŸ“‹ Indice

- [Panoramica del Progetto](#panoramica-del-progetto)
- [Architettura del Sistema](#architettura-del-sistema)
- [Struttura del Progetto](#struttura-del-progetto)
- [Dati e Schema](#dati-e-schema)
- [Pipeline ETL](#pipeline-etl)
- [Componente Machine Learning](#componente-machine-learning)
- [Setup e Installazione](#setup-e-installazione)
- [Utilizzo](#utilizzo)
- [Monitoraggio e Metriche](#monitoraggio-e-metriche)
- [Troubleshooting](#troubleshooting)
- [Contributi](#contributi)

---

## ğŸ¯ Panoramica del Progetto

GlobalStay Ã¨ un progetto di data engineering che implementa una pipeline ETL completa per l'elaborazione di dati di prenotazioni alberghiere, integrata con modelli di Machine Learning per la predizione dei prezzi.

### Obiettivi Principali:
- **ğŸ—ï¸ Architettura Medallion**: Implementazione Bronze/Silver/Gold layer
- **ğŸ”„ Orchestrazione Airflow**: Pipeline automatizzata e schedulabile
- **â˜ï¸ Integrazione Azure**: Storage e servizi cloud
- **ğŸ¤– Machine Learning**: Predizione prezzi e anomaly detection
- **ğŸ“Š Business Intelligence**: KPI e dashboard per decision making

### Tecnologie Utilizzate:
- **Orchestrazione**: Apache Airflow 2.7.3
- **Storage**: Azure Blob Storage
- **Processing**: Python, Pandas, PySpark
- **ML**: Scikit-learn, Random Forest
- **Monitoring**: Great Expectations, Pandera
- **Environment**: Conda, Docker-ready

---

## ğŸ›ï¸ Architettura del Sistema

### Medallion Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   LANDING ZONE  â”‚    â”‚  BRONZE LAYER   â”‚    â”‚  SILVER LAYER   â”‚    â”‚   GOLD LAYER    â”‚
â”‚                 â”‚    â”‚                 â”‚    â”‚                 â”‚    â”‚                 â”‚
â”‚  Raw CSV Files  â”‚â”€â”€â”€â–¶â”‚  Raw Ingestion  â”‚â”€â”€â”€â–¶â”‚ Data Quality &  â”‚â”€â”€â”€â–¶â”‚ KPIs & Business â”‚
â”‚  â€¢ hotels.csv   â”‚    â”‚  + Timestamps   â”‚    â”‚   Cleaning      â”‚    â”‚   Metrics       â”‚
â”‚  â€¢ rooms.csv    â”‚    â”‚  + Metadata     â”‚    â”‚  + Validation   â”‚    â”‚  + Aggregations â”‚
â”‚  â€¢ bookings.csv â”‚    â”‚  + Audit Trail  â”‚    â”‚  + Deduplicationâ”‚    â”‚  + ML Predictionsâ”‚
â”‚  â€¢ customers.csvâ”‚    â”‚                 â”‚    â”‚  + Standards    â”‚    â”‚                 â”‚
â”‚  â€¢ payments.csv â”‚    â”‚                 â”‚    â”‚                 â”‚    â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Flusso di Elaborazione:

1. **ğŸ“¥ Ingestion (Bronze)**: Caricamento 1:1 dei dati grezzi con metadata
2. **ğŸ§¹ Data Quality (Silver)**: Pulizia, validazione e standardizzazione
3. **ğŸ“Š Analytics (Gold)**: Calcolo KPI e metriche di business
4. **ğŸ¤– ML Enrichment**: Predizioni e anomaly detection

---

## ğŸ“ Struttura del Progetto

```
final_project/
â”œâ”€â”€ ğŸ“Š data/                              # Dataset sorgente
â”‚   â”œâ”€â”€ bookings.csv                      # Prenotazioni (6,000 records)
â”‚   â”œâ”€â”€ customers.csv                     # Anagrafica clienti (3,001 records)
â”‚   â”œâ”€â”€ hotels.csv                        # Anagrafica hotel (8 records)
â”‚   â”œâ”€â”€ payments.csv                      # Transazioni (4,595 records)
â”‚   â”œâ”€â”€ rooms.csv                         # Camere disponibili (201 records)
â”‚   â”œâ”€â”€ schema.sql                        # Schema database relazionale
â”‚   â””â”€â”€ README.txt                        # Descrizione dataset
â”‚
â”œâ”€â”€ ğŸš€ airflow_orchestration/             # Pipeline ETL
â”‚   â”œâ”€â”€ dags/
â”‚   â”‚   â”œâ”€â”€ globalstay_etl_dag.py        # DAG principale Airflow
â”‚   â”‚   â””â”€â”€ __pycache__/                 # Cache Python
â”‚   â””â”€â”€ scripts/
â”‚       â”œâ”€â”€ 01_ingestion.py              # Bronze Layer: Ingestion
â”‚       â”œâ”€â”€ 02_data_quality.py           # Silver Layer: Data Quality
â”‚       â”œâ”€â”€ 03_kpis.py                   # Gold Layer: KPI Generation
â”‚       â””â”€â”€ __init__.py                  # Modulo Python
â”‚
â”œâ”€â”€ ğŸ¤– ML/                               # Machine Learning
â”‚   â”œâ”€â”€ price_prediction_model.ipynb     # Notebook completo ML
â”‚   â”œâ”€â”€ grafici_ml/                      # Visualizzazioni generate
â”‚   â”‚   â”œâ”€â”€ 01_target_distribution.png
â”‚   â”‚   â”œâ”€â”€ 02_numeric_correlations.png
â”‚   â”‚   â”œâ”€â”€ 03_categorical_analysis.png
â”‚   â”‚   â”œâ”€â”€ 04_feature_importance.png
â”‚   â”‚   â”œâ”€â”€ 05_residual_analysis.png
â”‚   â”‚   â””â”€â”€ 06_performance_analysis.png
â”‚   â”œâ”€â”€ modelli/                         # Modelli addestrati
â”‚   â”‚   â”œâ”€â”€ price_prediction_model.joblib
â”‚   â”‚   â””â”€â”€ feature_config.joblib
â”‚   â””â”€â”€ risultati/                       # Output ML
â”‚       â”œâ”€â”€ model_metrics.joblib
â”‚       â””â”€â”€ bookings_with_predictions.csv
â”‚
â”œâ”€â”€ ğŸ“ Documentazione
â”‚   â”œâ”€â”€ README.md                        # Questo file
â”‚   â”œâ”€â”€ CLAUDE.md                        # Documentazione tecnica (ITA)
â”‚   â”œâ”€â”€ code_gen.md                      # Standard di sviluppo
â”‚   â””â”€â”€ guidelines.md                    # Linee guida del progetto
â”‚
â””â”€â”€ âš™ï¸ environment.yml                   # Ambiente Conda completo
```

---

## ğŸ“Š Dati e Schema

### Descrizione Dataset

Il dataset GlobalStay contiene **dati simulati** di prenotazioni alberghiere con **anomalie embedded** per testare la robustezza della pipeline di data quality.

### Tabelle e Volumi:

| Tabella | Records | Descrizione | Anomalie Presenti |
|---------|---------|-------------|-------------------|
| `hotels` | 8 | Anagrafica hotel | Country code 'XX' invalido |
| `rooms` | 201 | Camere per hotel | 1 riga duplicata |
| `customers` | 3,001 | Anagrafica clienti | Email vuote, 1 duplicato |
| `bookings` | 6,000 | Prenotazioni | Date invertite, importi negativi, currency 'XXX' |
| `payments` | 4,595 | Transazioni | Importi > totale booking, orphan booking_id |

### Schema Relazionale:

```sql
hotels (hotel_id PK, hotel_name, stars, country)
    â†“
rooms (room_id PK, hotel_id FK, room_type_code, room_type_desc, max_occupancy)
    â†“
bookings (booking_id PK, customer_id FK, hotel_id FK, room_id FK, 
         created_at, checkin_date, checkout_date, nights, 
         currency, total_amount, status, source)
    â†“
payments (payment_id PK, booking_id FK, provider, status, 
         amount, currency, transaction_date)

customers (customer_id PK, first_name, last_name, email, country, gdpr_optin)
```

---

## âš™ï¸ Pipeline ETL

### ğŸ¥‰ Bronze Layer - Ingestion (`01_ingestion.py`)

**Funzione**: `run_bronze_ingestion_task()`

**ResponsabilitÃ **:
- Caricamento 1:1 dei file CSV da landing zone
- Aggiunta timestamp di ingestion
- Preservazione completa dei dati grezzi
- Audit trail per tracciabilitÃ 

**Output**: `datalake/bronze/{table}/{table}.csv`

**Caratteristiche**:
- âœ… Zero trasformazioni dei dati
- âœ… Logging dettagliato
- âœ… Gestione errori robusta
- âœ… Metadata preservation

### ğŸ¥ˆ Silver Layer - Data Quality (`02_data_quality.py`)

**Funzione**: `run_silver_transformation_task()`

**Regole di Pulizia Implementate**:

#### Hotels:
- Rimozione country code 'XX' invalidi

#### Customers:
- Gestione email nulle (regex cleanup)
- Deduplicazione per `customer_id`

#### Rooms:
- Rimozione record duplicati per `room_id`

#### Bookings:
- Correzione automatica date invertite (checkin > checkout)
- Normalizzazione valute (EUR, USD, GBP)
- Gestione importi negativi â†’ NULL

#### Payments:
- Marcatura anomalie con flag:
  - `dq_orphan`: booking_id inesistente
  - `dq_over_amount`: importo > totale booking
- Normalizzazione valute

**Output**: `datalake/silver/{table}/{table}.csv`

### ğŸ¥‡ Gold Layer - KPIs (`03_kpis.py`)

**Funzione**: `run_gold_kpi_generation_task_pandas()`

**KPI Calcolati**:

1. **ğŸ“ˆ Daily Revenue**: Fatturato giornaliero per data check-in
2. **ğŸ“‰ Cancellation Rate**: Tasso cancellazioni per canale
3. **ğŸ’° Collection Rate**: Tasso incasso per hotel 
4. **âš ï¸ Overbooking Alerts**: Sovrapposizioni temporali camere
5. **ğŸ‘¤ Customer Value**: Metriche di valore per cliente

**Output**: `datalake/gold/{kpi_name}/{kpi_name}.csv`

### ğŸ¯ DAG Airflow (`globalstay_etl_dag.py`)

**Configurazione**:
- **ID**: `globalstay_full_etl_pipeline`
- **Schedule**: Trigger manuale
- **Retries**: 1
- **Max Active Runs**: 1

**Task Dependencies**:
```
ingest_to_bronze_layer â†’ transform_to_silver_layer â†’ generate_gold_layer_kpis
```

**Caratteristiche Tecniche**:
- âœ… Dynamic module loading per file numerati
- âœ… Robust error handling e logging
- âœ… Azure Storage integration
- âœ… Type hints e documentazione

---

## ğŸ¤– Componente Machine Learning

### Modello di Predizione Prezzi

**Notebook**: `ML/price_prediction_model.ipynb`

### Obiettivo:
Predire il `total_amount` delle prenotazioni per:
- Revenue optimization
- Anomaly detection
- Pricing dinamico

### Pipeline ML:

#### 1. **ğŸ“Š Feature Engineering**:
- **Temporali**: duration_of_stay, booking_month, season, is_weekend
- **Advance Booking**: days_in_advance  
- **Derivate**: price_per_night
- **Categoriche**: room_type_desc, country, season

#### 2. **ğŸ”§ Preprocessing**:
- StandardScaler per feature numeriche
- OneHotEncoder per feature categoriche
- Outlier removal (IQR method)
- Missing values handling

#### 3. **ğŸ¯ Modello**:
- **Algoritmo**: Random Forest Regressor
- **Parametri**: 200 estimators, max_depth=15
- **Validation**: Train/Test split 80/20

#### 4. **ğŸ“Š Performance**:
- **RÂ² Score**: 0.85+ (85% variabilitÃ  spiegata)
- **RMSE**: ~â‚¬122
- **MAE**: ~â‚¬89
- **Features piÃ¹ importanti**: duration_of_stay, max_occupancy, stars

#### 5. **ğŸ“ˆ Visualizzazioni**:
- Target distribution analysis
- Feature correlations  
- Categorical analysis
- Feature importance plots
- Residual analysis
- Performance evaluation

### Output ML:
- **Modello**: `ML/modelli/price_prediction_model.joblib`
- **Configurazione**: `ML/modelli/feature_config.joblib`
- **Metriche**: `ML/risultati/model_metrics.joblib`
- **Predizioni**: `ML/risultati/bookings_with_predictions.csv`
- **Grafici**: `ML/grafici_ml/*.png` (6 visualizzazioni)

---

## ğŸ› ï¸ Setup e Installazione

### Prerequisiti:
- Python 3.9+
- Conda/Miniconda
- Azure Storage Account (per produzione)
- Apache Airflow (installato via pip)

### 1. Clone del Repository:
```bash
git clone <repository-url>
cd final_project
```

### 2. Creazione Ambiente Conda:
```bash
conda env create -f environment.yml
conda activate globalstay-etl
```

### 3. Configurazione Azure (Produzione):
```bash
# Nel web UI di Airflow, creare connection:
# Conn Id: azure_storage_connection
# Conn Type: Azure Blob Storage
# Login: <storage_account_name>
# Password: <access_key>
```

### 4. Setup Airflow:
```bash
# Avvio scheduler
airflow scheduler

# Avvio webserver
airflow webserver --port 8080
```

---

## ğŸš€ Utilizzo

### Esecuzione Pipeline ETL:

1. **Via Airflow UI**:
   - Accedi a http://localhost:8080
   - Attiva DAG `globalstay_full_etl_pipeline`
   - Trigger manuale

2. **Via Command Line**:
```bash
airflow dags trigger globalstay_full_etl_pipeline
```

### Esecuzione ML Notebook:

1. **Avvio Jupyter**:
```bash
jupyter notebook ML/price_prediction_model.ipynb
```

2. **Esecuzione Completa**:
   - Run All Cells
   - Verifica output in `ML/risultati/`

### Monitoraggio Pipeline:

1. **Airflow Logs**: Task-level logging automatico
2. **Azure Storage**: Verifica blob containers
3. **ML Metrics**: Joblib files con metriche dettagliate

---

## ğŸ“Š Monitoraggio e Metriche

### Pipeline ETL:

#### Bronze Layer:
- âœ… **Success Rate**: 100% (6K records processed)
- âœ… **Latency**: <30 secondi per ingestion completa
- âœ… **Data Integrity**: Zero data loss

#### Silver Layer:
- âœ… **Data Quality**: 95%+ records cleaned
- âœ… **Anomaly Detection**: Automated flagging
- âœ… **Processing Time**: <60 secondi

#### Gold Layer:
- âœ… **KPI Generation**: 5 metriche di business
- âœ… **Completeness**: 100% coverage dati Silver
- âœ… **Performance**: Sub-minute execution

### Machine Learning:

#### Model Performance:
- ğŸ¯ **RÂ² Score**: 0.85 (Eccellente)
- ğŸ“ **RMSE**: â‚¬122 (Accettabile per business)
- ğŸ“ **MAE**: â‚¬89 (Robust performance)
- âš¡ **Training Time**: <5 minuti

#### Production Readiness:
- âœ… **Generalization**: No overfitting detected
- âœ… **Feature Stability**: Balanced importance
- âœ… **Bias Testing**: No systematic bias
- âš ï¸ **Heteroskedasticity**: Monitoring needed

---

## ğŸ”§ Troubleshooting

### Problemi Comuni:

#### 1. **Airflow DAG Import Error**:
```bash
# Soluzione: Verificare Python path
export PYTHONPATH="${PYTHONPATH}:/path/to/scripts"
```

#### 2. **Azure Connection Failed**:
```bash
# Verificare credentials in Airflow UI
# Admin â†’ Connections â†’ azure_storage_connection
```

#### 3. **Memory Issues ML**:
```python
# Ridurre dimensioni dataset per test
data_sample = data.sample(n=1000)
```

#### 4. **Dipendenze Mancanti**:
```bash
conda env update -f environment.yml
```

### Logging e Debug:

- **Airflow Logs**: `/airflow/logs/`
- **Python Logging**: Configurato per INFO level
- **Error Handling**: Try-catch con logging dettagliato

---

## ğŸ“ˆ Roadmap e Miglioramenti

### Short Term:
- [ ] Implementazione CI/CD pipeline
- [ ] Unit testing coverage
- [ ] Docker containerization
- [ ] Real-time streaming ingestion

### Medium Term:
- [ ] MLFlow integration per model versioning
- [ ] Apache Spark per scalabilitÃ 
- [ ] Data lineage tracking
- [ ] Advanced anomaly detection

### Long Term:
- [ ] Multi-cloud deployment
- [ ] Real-time ML serving
- [ ] Advanced analytics dashboard
- [ ] AutoML capabilities

---

## ğŸ‘¥ Contributi

### Team:
- **Data Engineering**: Pipeline ETL, Azure integration
- **Machine Learning**: Modelli predittivi, feature engineering
- **DevOps**: Orchestrazione, monitoring
- **Documentation**: Comprehensive project documentation

### Standards:
- **Code Quality**: PEP 8, type hints, docstrings
- **Testing**: Unit tests, integration tests
- **Documentation**: Markdown, inline comments
- **Version Control**: Git best practices

---

## ğŸ“„ Licenza

Questo progetto Ã¨ sviluppato per scopi educativi e dimostrativi nel contesto di data engineering e machine learning.

---

## ğŸ”— Link Utili

- [Apache Airflow Documentation](https://airflow.apache.org/docs/)
- [Azure Blob Storage](https://azure.microsoft.com/en-us/services/storage/blobs/)
- [Scikit-learn Documentation](https://scikit-learn.org/stable/)
- [Pandas Documentation](https://pandas.pydata.org/docs/)

---

**ğŸ¯ Progetto completato con successo! Pipeline ETL + ML fully operational** âœ…

*Generato automaticamente il 2025-09-22*